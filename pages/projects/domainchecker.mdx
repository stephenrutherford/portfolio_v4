import { NextSeo } from 'next-seo'
import { Prism as SyntaxHighlighter } from "react-syntax-highlighter"
import { materialDark } from "react-syntax-highlighter/dist/cjs/styles/prism"
import NextImage from 'next/image'
import NextLink from 'next/link'
import { Flex, Text, Icon, Stack, LinkBox, LinkOverlay } from "@chakra-ui/react"
import { FaGithub } from 'react-icons/fa'

<NextSeo {...
    {
        title: 'Domain Checker - Stephen Rutherford',
        description: 'A fraud investigation tool used to check for invalid and disposable email domains.',
        openGraph: {
            title: 'Domain Checker - Stephen Rutherford',
            description: 'A fraud investigation tool used to check for invalid and disposable email domains.',
            url: 'https://rutherford.dev/projects/domainchecker',
            type: 'article',
            article: {
            publishedTime: '2021-07-19T16:00:00Z',
            modifiedTime: '2021-07-19T16:00:00Z',
            section: 'Coding',
            tags: ['React', 'Next.js', 'JSX', 'JavaScript', 'Chakra-UI', 'Tailwind', 'Domain Checker', 'Domain' , 'Email', 'API', 'Node.js', 'Python', 'Django'],
            },
        },
    }
}
/>

# Domain Checker

<Promo
    source='/images/projects/domainchecker.mp4'
    githubSrc='https://github.com/stephenrutherford/dc3'
    demoSrc='https://dc3.vercel.app/'
 />

## Overview
A fraud investigation tool used to check for invalid and disposable email domains.

## Features
The app was built with Node and JavaScript in [Next.js](https://nextjs.org/) using the official API provided by [check-mail.org](https://check-mail.org/). The user can paste in the domains that they want to check, and the App will render a results table with additional columns that contain data of interest.

* Type - If the domain is considered disposable or not.
* Block - The domain is not disposable, but is high risk and should be blocked anyway.

An export button was also included for larger queries. The user may want to download the entire results table as a CSV file for filtering and spreadsheet lookups.

## Tech Specs
I am using [Next API routes](https://nextjs.org/docs/api-routes/introduction) as a server-side solution for the API endpoints. This takes additional load off the client with the additional bonus of keeping our API secrets hidden from the browser client.

<br />

The API endpoint receives an array of email domains then does a web request for each of these items. We return a `Promise.all()` event once the individual requests have completed and merge the specific data fields into a new JSON object. This JSON object is sent back to the client as a HTTP "200" response.

<br />

On the client side, we are waiting for this HTTP "200" response before the table of results can be updated. The form data is managed via [React Hooks](https://reactjs.org/docs/hooks-intro.html) which will be updated upon a successful API request.

## Code

<SyntaxHighlighter language='jsx' style={materialDark} showLineNumbers>
{`// ./pages/api/search.js
export default async (req, res) => {
    
    const body = JSON.parse(req.body);
    
    var axios = require("axios").default;
    
    const promiseArray = body.map(Item => {
        return axios(
            {
                "method": "GET",
                "url": "https://mailcheck.p.rapidapi.com/",
                "headers": {
                    "x-rapidapi-host": "mailcheck.p.rapidapi.com",
                    "x-rapidapi-key": \`\${process.env.API_KEY}\`
                }, "params": {
                    "domain": Item
                }
            }
        )
    })
    
    const mergedArray = []
        .concat
        .apply([], await axios.all(promiseArray))
        .map(e => e.data);
    
    return await res.status(200).json(mergedArray)
    
};`}
</SyntaxHighlighter>

<SyntaxHighlighter language='jsx' style={materialDark} showLineNumbers>
{`// ./pages/index.js
import Head from 'next/head'
import { Flex, Link, Heading, Stack, ... } from "@chakra-ui/react"
import { Select } from "@chakra-ui/select"
import { useState } from 'react'
import { CSVLink } from "react-csv";
    
export default function Home() {
    
    const [domains, setDomains] = useState([])
    const [input, setInput] = useState('')
    const [delimiter, setDelimiter] = useState(' ')
    
    async function handleOnSubmit(e) {
    e.preventDefault();
    
    let arr = input.split(delimiter)
    
    // Removes whitespace from array
    arr = arr.filter(function (str) {
        return /\S/.test(str)
    })
    
    const postsResponse = await fetch("/api/search", {
        method: 'post',
        body: JSON.stringify(arr)
    })
    const postsData = await postsResponse.json()
    setDomains(postsData)
    
    }
    
return (
    <Flex minW='100vw' minH='100vh' justifyContent='center'>
        <Head>
            <title>Domain Checker v3</title>
            <meta name="description" content="A tool to check for disposable and invalid domains." />
            <link rel="icon" href="/favicon.ico" />
        </Head>
        <Stack>
            <Heading>
                Domain Checker v3
            </Heading>
            {/* Input Form */}
            <Flex>
                <form onSubmit={handleOnSubmit}>
                    <Flex>
                    <Input 
                        value={input} onChange={(e) => { setInput(e.target.value) }}
                        isRequired
                    />
                    <Select 
                        onChange={(e) => { setDelimiter(e.target.value) }}
                        isRequired
                        defaultValue=" "
                    >
                        <option value=" ">Space</option>
                        <option value=",">Comma</option>
                    </Select>
                    </Flex>
                </form>
            </Flex>
            {/* Results Table */}
            <Flex
                display={domains.length > 0 ? 'inherit' : 'none'}>
            <Table>
                <Thead>
                    <Tr>
                        <Th>Domain</Th>
                        <Th>Disposable</Th>
                        <Th>Block</Th>
                    </Tr>
                </Thead>
                <Tbody>
                {domains.map((e) => (
                    <Tr key={e.domain}>
                    <Td>
                        <Link
                        href={\`https://check-mail.org/domain/\${e.domain}\`}
                        isExternal
                        >
                            {e.domain}
                        </Link>
                    </Td>
                    <Td>{e.disposable ? e.disposable.toString().toUpperCase() : ""}</Td>
                    <Td>{e.block ? e.block.toString().toUpperCase() : ""}</Td>
                    </Tr>
                ))}
                </Tbody>
                <Tfoot>
                <Tr>
                    <Th>Domain</Th>
                    <Th>Disposable</Th>
                    <Th>Block</Th>
                </Tr>
                </Tfoot>
            </Table>
            </Flex>
            {/* CSV Download */}
            <CSVLink filename={"domain_results.csv"} data={domains.map((e) => (e))}>
                <Button display={domains.length > 0 ? 'inherit' : 'none'}>
                    Download as CSV
                </Button>
            </CSVLink>
        </Stack>
    </Flex >
  )
}`}
</SyntaxHighlighter>

---

## Bonus

Heres an older version of the app that was writen as a webscraping tool. This version was built with Python using Django.

<SyntaxHighlighter language='python' style={materialDark} showLineNumbers>
{`# views.py
from django.shortcuts import render
from django.http import HttpResponse
import requests
from bs4 import BeautifulSoup
    
# Create your views here.
render_list = []
    
def scrape_domain(domain):
    base = "https://check-mail.org/domain/"
    url = base+domain
    r = requests.get(url)
    soup = BeautifulSoup(r.text, "html.parser")
    domain_data = []
    for h5 in soup.find_all("h5"):
        values = h5.text
        domain_data.append(values)
    return print_domain_details(domain, domain_data)
    
def print_domain_details(domain, domain_data):
    domain_dict = {}
    for i in domain_data:
        if i == "Disposable: Yes":
            domain_dict["domain"] = domain
            domain_dict["disposable"] = "DISPOSABLE"
        elif i == "Disposable: No":
            domain_dict["domain"] = domain
    render_list.append(domain_dict)
    
def index(request):
    context = None
    if request.method == "POST":
        # Clear list on new load
        render_list.clear()
        domains = request.POST.get("textfield", None).split()
            
        for domain in domains:
            scrape_domain(domain)
            
        # Render user submitted context on same page
        context = {"render_list" : render_list}
        return render(request, "pages/home.html", context)
    return render(request, "pages/home.html", context)`}
</SyntaxHighlighter>